name: Process Allure Test Results

on:
  workflow_dispatch:
    inputs:
      s3_directory:
        description: 'S3 Directory Path (e.g., Result/consul/2025-12-10/00-42-50/)'
        required: true
        type: string
  repository_dispatch:
    types: [s3-new-consul-directory]
  #schedule:
    # Optional: Run every 30 minutes to check for new results
    #- cron: '*/30 * * * *'

env:
  S3_BUCKET: qstp-consul
  OUTPUT_DIR: ./allure-report
  SINGLE_FILE_DIR: ./allure-single-file

jobs:
  generate-allure-report:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Parse S3 directory path
        id: parse_path
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            S3_DIR="${{ github.event.inputs.s3_directory }}"
          elif [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            S3_DIR="${{ github.event.client_payload.directory }}"
          else
            # For scheduled runs, find latest directory
            S3_DIR=$(aws s3 ls "s3://$S3_BUCKET/Result/consul/" --recursive | grep '/$' | sort -r | head -1 | awk '{print $4}' | sed 's/\/$//')
            if [ -z "$S3_DIR" ]; then
              echo "No directories found"
              exit 0
            fi
          fi
          
          # Remove trailing slash if present
          S3_DIR=${S3_DIR%/}
          echo "S3_DIR=$S3_DIR" >> $GITHUB_OUTPUT
          
          # Extract timestamp path for report
          # Convert Result/consul/2025-12-10/00-42-50/ to 2025-12-10/00-42-50
          TIMESTAMP_PATH=$(echo "$S3_DIR" | sed 's|^Result/consul/||')
          echo "TIMESTAMP_PATH=$TIMESTAMP_PATH" >> $GITHUB_OUTPUT
          
          # Extract date and time separately
          DATE_PART=$(echo "$TIMESTAMP_PATH" | cut -d'/' -f1)
          TIME_PART=$(echo "$TIMESTAMP_PATH" | cut -d'/' -f2)
          echo "DATE=$DATE_PART" >> $GITHUB_OUTPUT
          echo "TIME=$TIME_PART" >> $GITHUB_OUTPUT
          
          # Create safe identifier
          SAFE_ID="${DATE_PART}_${TIME_PART}"
          echo "SAFE_ID=$SAFE_ID" >> $GITHUB_OUTPUT
          
          echo "Parsed path: $S3_DIR"
          echo "Timestamp path: $TIMESTAMP_PATH"
          echo "Safe ID: $SAFE_ID"

      - name: Check if report already exists
        id: check_report
        run: |
          REPORT_PATH="Report/consul/${{ steps.parse_path.outputs.TIMESTAMP_PATH }}/"
          echo "Checking if report exists at: $REPORT_PATH"
          
          # Check if multi-file report exists
          if aws s3 ls "s3://$S3_BUCKET/$REPORT_PATH" --recursive | head -1; then
            echo "Report already exists"
            echo "EXISTS=true" >> $GITHUB_OUTPUT
          else
            echo "EXISTS=false" >> $GITHUB_OUTPUT
          fi

      - name: Download test results from S3
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          echo "Downloading test results from: s3://$S3_BUCKET/${{ steps.parse_path.outputs.S3_DIR }}/"
          mkdir -p ./s3-data
          aws s3 sync "s3://$S3_BUCKET/${{ steps.parse_path.outputs.S3_DIR }}/" ./s3-data/ --exclude "*" --include "*.xml" --include "*.json" --include "*.txt"
          
          # List downloaded files
          echo "Downloaded files:"
          find ./s3-data -type f | head -20
          echo "Total files: $(find ./s3-data -type f | wc -l)"
          
          # Check if we have any test files
          if [ ! "$(find ./s3-data -type f -name '*.xml' -o -name '*.json')" ]; then
            echo "No test result files found"
            exit 1
          fi

      - name: Install Allure
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          # Install Java (required for Allure)
          sudo apt-get update
          sudo apt-get install -y openjdk-11-jre
          
          # Download and install Allure
          curl -Lo allure-2.24.0.tgz https://github.com/allure-framework/allure2/releases/download/2.24.0/allure-2.24.0.tgz
          sudo tar -zxvf allure-2.24.0.tgz -C /opt/
          sudo ln -sf /opt/allure-2.24.0/bin/allure /usr/bin/allure
          
          # Verify installation
          allure --version
          
          # Also install allure command line via npm (alternative)
          sudo apt-get install -y npm
          sudo npm install -g allure-commandline

      - name: Generate Allure Report (Multi-file)
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          echo "Generating multi-file Allure report..."
          allure generate ./s3-data/ -o "$OUTPUT_DIR" --clean
          
          # Check if report was generated
          if [ -f "$OUTPUT_DIR/index.html" ]; then
            echo "âœ… Report generated successfully"
            echo "Report size: $(du -sh $OUTPUT_DIR)"
          else
            echo "âŒ Failed to generate report"
            ls -la $OUTPUT_DIR/
            exit 1
          fi

      - name: Upload Multi-file Report to S3
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          REPORT_PATH="Report/consul/${{ steps.parse_path.outputs.TIMESTAMP_PATH }}/multi-file/"
          echo "Uploading multi-file report to: s3://$S3_BUCKET/$REPORT_PATH"
          
          # Upload with public read access (adjust as needed)
          aws s3 sync "$OUTPUT_DIR/" "s3://$S3_BUCKET/$REPORT_PATH" \
            --acl bucket-owner-full-control \
            --cache-control "max-age=3600"
          
          # Generate URL for the report
          echo "REPORT_URL=https://$S3_BUCKET.s3.amazonaws.com/${REPORT_PATH}index.html" >> $GITHUB_ENV
          echo "ðŸ“Š Multi-file report available at: $REPORT_URL"

      - name: Generate Single File Report
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          echo "Generating single-file Allure report..."
          allure generate ./s3-data/ -o "$SINGLE_FILE_DIR" --single-file --clean
          
          # Find the generated file
          SINGLE_FILE=$(find "$SINGLE_FILE_DIR" -name "*.html" -o -name "*.json" | head -1)
          if [ -n "$SINGLE_FILE" ]; then
            mv "$SINGLE_FILE" "$SINGLE_FILE_DIR/allure-report-${{ steps.parse_path.outputs.SAFE_ID }}.html"
            echo "âœ… Single-file report generated: allure-report-${{ steps.parse_path.outputs.SAFE_ID }}.html"
          else
            echo "âŒ Failed to generate single-file report"
            exit 1
          fi

      - name: Upload Single File Report to S3
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          REPORT_PATH="Report/consul/${{ steps.parse_path.outputs.TIMESTAMP_PATH }}/"
          SINGLE_FILE_NAME="allure-report-${{ steps.parse_path.outputs.SAFE_ID }}.html"
          
          echo "Uploading single-file report to: s3://$S3_BUCKET/$REPORT_PATH"
          
          # Upload single file
          aws s3 cp "$SINGLE_FILE_DIR/$SINGLE_FILE_NAME" "s3://$S3_BUCKET/$REPORT_PATH$SINGLE_FILE_NAME" \
            --acl bucket-owner-full-control \
            --cache-control "max-age=3600"
          
          # Generate direct download URL
          echo "SINGLE_FILE_URL=https://$S3_BUCKET.s3.amazonaws.com/${REPORT_PATH}${SINGLE_FILE_NAME}" >> $GITHUB_ENV
          echo "ðŸ“¥ Single file download: $SINGLE_FILE_URL"

      - name: Create Summary File
        if: steps.check_report.outputs.EXISTS == 'false'
        run: |
          SUMMARY_PATH="./summary.json"
          cat > $SUMMARY_PATH << EOF
          {
            "timestamp": "${{ steps.parse_path.outputs.TIMESTAMP_PATH }}",
            "date": "${{ steps.parse_path.outputs.DATE }}",
            "time": "${{ steps.parse_path.outputs.TIME }}",
            "source": "${{ steps.parse_path.outputs.S3_DIR }}",
            "report_url": "${{ env.REPORT_URL }}",
            "single_file_url": "${{ env.SINGLE_FILE_URL }}",
            "generated_at": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
            "workflow_run": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          }
          EOF
          
          # Upload summary to S3
          REPORT_PATH="Report/consul/${{ steps.parse_path.outputs.TIMESTAMP_PATH }}/"
          aws s3 cp "$SUMMARY_PATH" "s3://$S3_BUCKET/$REPORT_PATH"summary.json \
            --acl bucket-owner-full-control

      - name: Create Workflow Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: consul-report-${{ steps.parse_path.outputs.SAFE_ID }}
          path: |
            ${{ env.OUTPUT_DIR }}
            ${{ env.SINGLE_FILE_DIR }}
          retention-days: 7

      - name: Output Report Links
        run: |
          echo "ðŸš€ Allure Report Generation Complete!"
          echo "======================================"
          echo ""
          echo "ðŸ“… Test Run: ${{ steps.parse_path.outputs.DATE }} ${{ steps.parse_path.outputs.TIME }}"
          echo ""
          echo "ðŸ“Š Interactive Report:"
          echo "${{ env.REPORT_URL }}"
          echo ""
          echo "ðŸ“¥ Single File Download:"
          echo "${{ env.SINGLE_FILE_URL }}"
          echo ""
          echo "ðŸ”— Direct Download Command:"
          echo "curl -LO '${{ env.SINGLE_FILE_URL }}'"
          echo ""
          echo "ðŸ“ S3 Location:"
          echo "s3://$S3_BUCKET/Report/consul/${{ steps.parse_path.outputs.TIMESTAMP_PATH }}/"
          echo ""
          echo "â° Generated at: $(date)"

      - name: Send Notification (Optional)
        if: success()
        run: |
          # Example: Send notification to Slack, Teams, etc.
          echo "Report generation completed successfully!"
          # Add your notification logic here