name: Process Consul Test Results

on:
  workflow_dispatch:
    inputs:
      s3_directory:
        description: 'S3 Directory Path (e.g., Result/consul/2025-12-10/00-42-50/)'
        required: true
        default: 'Result/consul/2025-12-10/00-42-50'
        type: string
  repository_dispatch:
    types: [s3-new-consul-directory]

env:
  S3_BUCKET: qstp-consul
  OUTPUT_DIR: ./allure-report
  SINGLE_FILE_DIR: ./allure-single-file

jobs:
  generate-allure-report:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION || 'us-east-1' }}

      - name: Setup and debug
        id: setup
        run: |
          echo "GitHub Event: ${{ github.event_name }}"
          echo "GitHub Ref: ${{ github.ref }}"
          echo "GitHub SHA: ${{ github.sha }}"
          
          # Parse S3 directory from input
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            S3_DIR="${{ github.event.inputs.s3_directory }}"
            echo "Using manual input: $S3_DIR"
          elif [ "${{ github.event_name }}" == "repository_dispatch" ]; then
            S3_DIR="${{ github.event.client_payload.directory }}"
            echo "Using repository dispatch: $S3_DIR"
          else
            echo "Unknown trigger"
            exit 1
          fi
          
          # Remove trailing slash if present
          S3_DIR=${S3_DIR%/}
          echo "S3_DIR=$S3_DIR" >> $GITHUB_OUTPUT
          
          # Extract timestamp path for report
          # Convert Result/consul/2025-12-10/00-42-50 to 2025-12-10/00-42-50
          TIMESTAMP_PATH=$(echo "$S3_DIR" | sed 's|^Result/consul/||')
          echo "TIMESTAMP_PATH=$TIMESTAMP_PATH" >> $GITHUB_OUTPUT
          
          # Create safe identifier
          SAFE_ID=$(echo "$TIMESTAMP_PATH" | sed 's|/|_|g' | sed 's|-|_|g')
          echo "SAFE_ID=$SAFE_ID" >> $GITHUB_OUTPUT
          
          echo "Parsed S3 directory: $S3_DIR"
          echo "Report path: Report/consul/$TIMESTAMP_PATH"
          echo "Safe ID: $SAFE_ID"
          
          # List S3 bucket to verify access
          echo "Listing S3 bucket root:"
          aws s3 ls "s3://$S3_BUCKET/" || true
          
          echo "Checking if source directory exists:"
          aws s3 ls "s3://$S3_BUCKET/$S3_DIR/" || echo "Directory might be empty or not exist"

      - name: Download test results from S3
        run: |
          echo "Downloading from: s3://$S3_BUCKET/${{ steps.setup.outputs.S3_DIR }}/"
          mkdir -p ./s3-data
          
          # Try to sync all files
          aws s3 sync "s3://$S3_BUCKET/${{ steps.setup.outputs.S3_DIR }}/" ./s3-data/ --quiet
          
          # Check what was downloaded
          echo "Downloaded files in s3-data:"
          find ./s3-data -type f | head -20 || echo "No files found"
          echo "Total files: $(find ./s3-data -type f 2>/dev/null | wc -l || echo 0)"
          
          # If no files, try listing what's in S3
          echo "Listing files in S3 source:"
          aws s3 ls "s3://$S3_BUCKET/${{ steps.setup.outputs.S3_DIR }}/" --recursive || true

      - name: Install dependencies
        run: |
          # Update package list
          sudo apt-get update
          
          # Install Java 11 (required for Allure)
          sudo apt-get install -y openjdk-11-jre
          
          # Install curl and unzip
          sudo apt-get install -y curl unzip
          
          # Verify Java installation
          java -version

      - name: Install Allure
        run: |
          # Download Allure
          echo "Downloading Allure..."
          curl -L -o allure-2.24.0.zip https://github.com/allure-framework/allure2/releases/download/2.24.0/allure-2.24.0.zip
          
          # Extract Allure
          unzip allure-2.24.0.zip -d /opt/
          
          # Create symlink
          sudo ln -sf /opt/allure-2.24.0/bin/allure /usr/local/bin/allure
          
          # Verify installation
          allure --version || echo "Allure not in PATH"
          /opt/allure-2.24.0/bin/allure --version

      - name: Generate Allure Report
        id: generate_report
        run: |
          # Check if we have any test result files
          if find ./s3-data -name "*.xml" -o -name "*.json" | head -1 > /dev/null; then
            echo "Found test result files"
          
            # Generate multi-file report
            echo "Generating multi-file report..."
            /opt/allure-2.24.0/bin/allure generate ./s3-data/ -o "$OUTPUT_DIR" --clean
          
            # Generate single-file report
            echo "Generating single-file report..."
            /opt/allure-2.24.0/bin/allure generate ./s3-data/ -o "$SINGLE_FILE_DIR" --single-file --clean
          
            # Check if reports were generated
            if [ -f "$OUTPUT_DIR/index.html" ]; then
              echo "Multi-file report generated successfully"
              echo "HAS_REPORT=true" >> $GITHUB_OUTPUT
            else
              echo "Multi-file report generation failed"
              echo "HAS_REPORT=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "No test result files found in ./s3-data"
            echo "Contents of s3-data:"
            ls -la ./s3-data/
            echo "HAS_REPORT=false" >> $GITHUB_OUTPUT
          fi

      - name: Upload Reports to S3
        if: steps.generate_report.outputs.HAS_REPORT == 'true'
        run: |
          # Define report paths
          REPORT_BASE_PATH="Report/consul/${{ steps.setup.outputs.TIMESTAMP_PATH }}"
          
          echo "Uploading reports to S3..."
          echo "Base path: $REPORT_BASE_PATH"
          
          # Upload multi-file report
          echo "Uploading multi-file report..."
          aws s3 sync "$OUTPUT_DIR/" "s3://$S3_BUCKET/$REPORT_BASE_PATH/multi-file/" \
            --quiet
          
          # Find and upload single file report
          SINGLE_FILE=$(find "$SINGLE_FILE_DIR" -name "*.html" -o -name "*.json" | head -1)
          if [ -n "$SINGLE_FILE" ]; then
            SINGLE_FILE_NAME="allure-report-${{ steps.setup.outputs.SAFE_ID }}.html"
            echo "Uploading single file: $SINGLE_FILE_NAME"
          
            aws s3 cp "$SINGLE_FILE" "s3://$S3_BUCKET/$REPORT_BASE_PATH/$SINGLE_FILE_NAME" \
              --quiet
          
            # Generate download URL
            SINGLE_FILE_URL="https://$S3_BUCKET.s3.amazonaws.com/$REPORT_BASE_PATH/$SINGLE_FILE_NAME"
            echo "SINGLE_FILE_URL=$SINGLE_FILE_URL" >> $GITHUB_ENV
          else
            echo "No single file found"
          fi
          
          # Create report URL for multi-file
          REPORT_URL="https://$S3_BUCKET.s3.amazonaws.com/$REPORT_BASE_PATH/multi-file/index.html"
          echo "REPORT_URL=$REPORT_URL" >> $GITHUB_ENV
          
          # Create a simple summary file
          SUMMARY_FILE="./report-summary.txt"
          cat > "$SUMMARY_FILE" << EOF
          Allure Report Summary
          =====================
          Timestamp: ${{ steps.setup.outputs.TIMESTAMP_PATH }}
          Source: ${{ steps.setup.outputs.S3_DIR }}
          
          Report Links:
          - Interactive Report: $REPORT_URL
          - Single File Download: $SINGLE_FILE_URL
          
          Generated at: $(date)
          EOF
          
          aws s3 cp "$SUMMARY_FILE" "s3://$S3_BUCKET/$REPORT_BASE_PATH/summary.txt"

      - name: Create Artifacts
        if: steps.generate_report.outputs.HAS_REPORT == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: consul-report-${{ steps.setup.outputs.SAFE_ID }}
          path: |
            ${{ env.OUTPUT_DIR }}
            ${{ env.SINGLE_FILE_DIR }}
            ./s3-data/
          retention-days: 7

      - name: Output Results
        run: |
          echo "========================================"
          echo "GitHub Action Run Complete"
          echo "========================================"
          echo ""
          echo "Workflow: ${{ github.workflow }}"
          echo "Run ID: ${{ github.run_id }}"
          echo "Run Number: ${{ github.run_number }}"
          echo ""
          
          if [ "${{ steps.generate_report.outputs.HAS_REPORT }}" = "true" ]; then
            echo "âœ… Report Generation Successful"
            echo ""
            echo "ðŸ“Š Interactive Report:"
            echo "${{ env.REPORT_URL }}"
            echo ""
            echo "ðŸ“¥ Single File Download:"
            echo "${{ env.SINGLE_FILE_URL }}"
            echo ""
            echo "ðŸ“ S3 Location:"
            echo "s3://$S3_BUCKET/Report/consul/${{ steps.setup.outputs.TIMESTAMP_PATH }}/"
          else
            echo "âš ï¸ No report generated"
            echo "Check if test files exist in: s3://$S3_BUCKET/${{ steps.setup.outputs.S3_DIR }}/"
            echo ""
            echo "Debug info:"
            echo "- S3 directory: ${{ steps.setup.outputs.S3_DIR }}"
            echo "- Downloaded files count: $(find ./s3-data -type f 2>/dev/null | wc -l || echo 0)"
          fi

      - name: Send Slack Notification (Optional)
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          fields: workflow,job,commit,message,author
          author_name: GitHub Actions
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}