name: Upload Allure Results (Python Script)

on:
  schedule:
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      target_date:
        description: 'Target date (YYYY-MM-DD)'
        required: false
        default: ''
      source_bucket:
        description: 'Source S3 bucket'
        required: false
        default: 'consul-test'
      destination_bucket:
        description: 'Destination S3 bucket'
        required: false
        default: 'qstp-consul-allure'

env:
  SOURCE_BUCKET: 'consul-test'
  DESTINATION_BUCKET: 'qstp-consul-allure'
  AWS_REGION: 'us-east-1'

jobs:
  process-and-upload:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: List S3 directories for today
        id: list-s3
        run: |

          BUCKET_NAME="${{ vars.QSTP_S3_BUCKET_NAME }}"
          echo "Looking for subdirectories in: s3://$BUCKET_NAME/$TODAY/"
          
          SUBDIRS=$(aws s3api list-objects-v2 \
            --bucket "$BUCKET_NAME" \
            --prefix "$TODAY/" \
            --delimiter "/" \
            --query "CommonPrefixes[].Prefix" \
            --output text 2>/dev/null || echo "")
          
          if [ -z "$SUBDIRS" ]; then
            echo "No subdirectories found for date: $TODAY"
            echo "subdirs_list=" >> $GITHUB_OUTPUT
          else
            echo "Found subdirectories:"
            echo "$SUBDIRS" | tr '\t' '\n'
          
            SUBDIRS_JSON=$(echo "$SUBDIRS" | tr '\t' '\n' | jq -R -s -c 'split("\n") | map(select(. != ""))')
            echo "subdirs_list=$SUBDIRS_JSON" >> $GITHUB_OUTPUT
          fi

      - name: Run processing script
        env:
          TARGET_DATE: ${{ github.event.inputs.target_date || '' }}
          SOURCE_BUCKET: ${{ github.event.inputs.source_bucket || env.SOURCE_BUCKET }}
          DEST_BUCKET: ${{ github.event.inputs.destination_bucket || env.DESTINATION_BUCKET }}
        run: |
          python allure-report/process_s3_folders.py