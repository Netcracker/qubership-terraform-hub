name: Process and Upload Allure Results

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  # Also allow manual trigger
  workflow_dispatch:
    inputs:
      target_date:
        description: 'Target date (YYYY-MM-DD)'
        required: false
        default: ''
      source_bucket:
        description: 'Source S3 bucket'
        required: false
        default: 'consul-test'
      destination_bucket:
        description: 'Destination S3 bucket'
        required: false
        default: 'qstp-consul-allure'

env:
  SOURCE_BUCKET: 'consul-test'
  DESTINATION_BUCKET: 'qstp-consul-allure'
  AWS_REGION: 'us-east-1'

jobs:
  process-folders:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install boto3
        run: pip install boto3

      - name: Run folder processing script
        env:
          TARGET_DATE: ${{ github.event.inputs.target_date || '' }}
          SOURCE_BUCKET: ${{ github.event.inputs.source_bucket || env.SOURCE_BUCKET }}
          DEST_BUCKET: ${{ github.event.inputs.destination_bucket || env.DESTINATION_BUCKET }}
          AWS_REGION: ${{ env.AWS_REGION }}
        run: |
          python allure-report/process_s3_folders.py

      - name: Upload processing log
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: processing-log
          path: ${{ github.workspace }}/processing.log
          retention-days: 7